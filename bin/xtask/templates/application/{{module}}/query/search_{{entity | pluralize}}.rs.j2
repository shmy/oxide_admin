use bon::Builder;
use infrastructure::shared::{cloneable_error::CloneableError, pg_pool::PgPool};
use nject::injectable;
use serde::Deserialize;
use serde_with::serde_as;
use std::time::Duration;
use single_flight::single_flight;

use crate::{
    {{module}}::dto::{{entity}}::{{entity | pascal_case}}Dto,
    impl_static_cache,
    shared::{
        cache_type::{CacheType, hash_encode},
        paging_query::PagingQuery,
        paging_result::PagingResult,
    },
};

const CACHE_CAPACITY: u64 = 100;
const CACHE_TTL: Duration = Duration::from_secs(15 * 60);

impl_static_cache!(
    SEARCH_CACHE,
    PagingResult<{{entity | pascal_case}}Dto>,
    CACHE_CAPACITY,
    CACHE_TTL
);

#[serde_as]
#[derive(Clone, Eq, PartialEq, Hash, Deserialize, Builder)]
pub struct Search{{entity | pluralize | pascal_case}}Query {
    #[serde(flatten)]
    paging: PagingQuery,
}

#[derive(Clone)]
#[injectable]
pub struct Search{{entity | pluralize | pascal_case}}QueryHandler {
    pool: PgPool,
    #[inject(&SEARCH_CACHE)]
    cache: &'static CacheType<PagingResult<{{entity | pascal_case}}Dto>>,
}

impl Search{{entity | pluralize | pascal_case}}QueryHandler {
    #[single_flight]
    pub async fn query(
        &self,
        query: Search{{entity | pluralize | pascal_case}}Query,
    ) -> Result<PagingResult<{{entity | pascal_case}}Dto>, CloneableError> {
        let total_future = sqlx::query_scalar!(
            r#"
            SELECT COUNT(*) AS "count!"
            FROM {{table_name}}
            "#,
        )
        .fetch_one(&self.pool);
        let page = query.paging.page();
        let page_size = query.paging.page_size();
        let offset = (page - 1) * page_size;
        let rows_future = sqlx::query_as!(
            {{entity | pascal_case}}Dto,
            r#"
        SELECT {{fields | map(attribute="name") | join(', ')}}
        FROM {{table_name}}
        LIMIT $1 OFFSET $2
        "#,
            page_size,
            offset,
        )
        .fetch_all(&self.pool);
        let (total, rows) = tokio::try_join!(total_future, rows_future)?;
        Ok(PagingResult { total, items: rows })
    }

    pub fn clean_cache(&self) {
        self.cache.invalidate_all();
    }

    pub async fn query_cached(
        &self,
        query: Search{{entity | pluralize | pascal_case}}Query,
    ) -> Result<PagingResult<{{entity | pascal_case}}Dto>, CloneableError> {
        let key = hash_encode(&query);
        self.cache.get_with(key, self.query(query)).await
    }
}
